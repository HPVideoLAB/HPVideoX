export default {
  meau: {
    nav1: "模型",
    nav2: "矿工",
    nav3: "学习",
    nav4: "创作者",
    nav5: "博客",
    nav6: "学院",
    nav7: "帮助中心",
    nav8: "HPVideo 的使用方式",
    nav9: "前往 HPVideo"
  },
  home: {
    cont1: {
      title1: "HPVideo",
      title2: "基于 BNB 链的去中心化 AI 视频生成平台",
      title3: "HPVideo 是一个基于钱包的去中心化 AI 视频生成平台，运行于 BNB 链上，提供快速、低成本的视频创建功能，支持多种 AI 模型——无需邮箱，无需提供个人数据",
      text1: "10 倍速度",
      text2: "成本",
      btn: "开始创作",
      model1: {
        text: "特色与优点：作为行业标杆，以其对物理世界的深刻理解和模拟能力著称。能生成具有复杂场景、连贯角色和多角度镜头切换的电影级视频，尤其在保持物体运动符合真实物理规律方面表现突出。",
        tips: "一段电影级预告片：一头雄伟的长毛猛犸从北极雾气弥漫的雪林中缓缓出现，长长的毛发随步伐真实摆动，在金色夕阳下吐出一团团白色热气，全程通过富有动感的镜头运动进行拍摄。"
      },
      model2: {
        text: "特色与优点：专注于生成高质量、视觉连贯的长视频（可长达一分钟或更久）。在角色、风格和场景在整个视频时长内的一致性方面具有优势，适合创作具有完整起承转合结构的微短片故事。",
        tips: "一段连续 60 秒的镜头，跟随一位孤独宇航员在一颗充满色彩的外星行星上迈出第一步。视频从靴子踩在会发光的苔藓上的特写开始，随后镜头上移映出头盔中他惊叹的表情，最后切到广角镜头，呈现双月照耀下令人屏息的荧光景观。"
      },
      model3: {
        text: "特色与优点：以其先进的物理引擎和高质量、高动态范围的视频生成闻名。特别擅长模拟复杂物体运动、流体动力学（如水、烟雾）以及真实光影交互，生成动作逼真、充满动感的场景。",
        tips: "一段水球在强烈阳光下撞击水泥墙的慢动作视频，捕捉每个细节：碰撞瞬间、水体形成完美球形的一刻，再到水球炸裂成数千颗闪耀水滴，以及墙面上光影跳动的变化。"
      },
      model4: {
        text: "特色与优点：在动态表现和画面细节之间取得良好平衡。生成的视频不仅动作流畅自然，在角色表情、材质纹理（如皮肤、布料、金属）和场景细节上也十分逼真，整体视觉质感出色。",
        tips: "一段极致细节的特写：一位技艺精湛的工匠正在塑形一团炽热的玻璃。视频聚焦于玻璃流动的形态、炽热的光晕、工具的质感，以及工匠脸上专注的表情，整个过程动作平滑连贯。"
      },
      model5: {
        text: "特色与优点：作为一款集成式 AI 视频创作套件，其优势在于用户可控度与逼真细节。提供更精细的控制参数（如镜头运动、角色一致性），擅长生成人物动作流畅、表情生动的叙事性视频。",
        tips: "一段悬疑短片场景：侦探在昏暗的图书馆里慢慢打开一本布满灰尘的旧书。镜头聚焦于他谨慎的表情、光束中飞舞的尘埃，以及书页间被发现的隐藏地图，配合戏剧性的光影。"
      },
      model6: {
        text: "特色与优点：能灵活生成不同分辨率的视频（从社交媒体竖屏到影院宽屏），并重视音频（如背景音乐、音效）与画面的高质量同步生成，带来更加沉浸的体验。",
        tips: "一段 9:16 竖屏的赛博朋克风社交媒体短视频：一名 DJ 在霓虹灯点亮的天台俱乐部演出。画面中跳动的特效和人群的动作与原创电子乐的节奏完美同步。"
      },
      model7: {
        text: "特色与优点：强调“动态场景的逼真渲染”，尤其擅长处理宏大且充满动态元素的画面，例如大规模自然现象（风暴、海浪）、战场、繁忙的城市交通或人群模拟，并以逼真的光影和物理效果进行渲染。",
        tips: "一段扫过中世纪战场的空中镜头，时间为黄昏，成千上万的士兵正在厮杀。画面包含逼真的骑兵冲锋、箭雨飞舞、燃烧火堆升起的烟雾，以及在风中剧烈摆动的战旗，整体呈现电影级规模。"
      },
      model8: {
        text: "特色与优点：主打“多镜头叙事，画面稳定流畅”。专为自动生成包含多个分镜（如特写、中景、全景）的短视频而设计，镜头切换平滑稳定，非常适合快速创建具有分镜感的短片或广告。",
        tips: "一段约 30 秒的默片风格叙事，讲述一封失而复得的信件：1）特写镜头：一封旧信静静躺在信箱里；2）中景镜头：邮差骑着自行车穿行在雨中的街道；3）平滑切换到收信人惊喜微笑的特写。"
      }
    },
    cont2: {
      title: "我可以帮你做什么？",
      text1: "一根洁白的羽毛在雷电闪烁的乌云间上下翻飞，轻盈起舞，最终被卷入翻滚的风暴漩涡，在混乱的天空中留下一道安然静谧的轨迹。",
      text2: "浓黑的墨滴落入清澈的水中，缓缓扩散、交织，如同宇宙星云在杯中绽放，在宁静的玻璃世界里展开一片不断变化的抽象深海。",
      text3: "一只用旧地图折成的小纸船勇敢地顺着雨水沟漂流，雨水被城市霓虹映成流动的光河，它在这条映照都市灯火的迷你河道中一路航行。",
      text4: "一只优雅的折纸仙鹤在阳光洒落的木桌上自己展开，纸面随着神奇的节奏慢慢抚平，最终回到一张平整的纸张，留下满是记忆的折痕。",
      text5: "一整座未来城市的绚丽倒影映在一滩雨水中，随着一滴水滴落下，水面泛起涟漪，城市影像被撕裂重组，仿佛一幅流动的抽象油画。"
    },
    cont3: {
      title1: "去中心化智能核心",
      text1_1: "分布式算力",
      text1_2: "AI 深度集成",
      text1_3: "可信生成",
      text1_4: "高效创作",
      title2: "从文字到运动画面",
      text2_1: "文本输入",
      text2_2: "逐帧构建",
      text2_3: "画面生成",
      text2_4: "高质量输出",
      title3: "创意真正归你所有",
      text3_1: "创意时间戳",
      text3_2: "透明生成过程",
      text3_3: "价值受保护",
      text3_4: "所有权有保障",
      title4: "开放式共创",
      text4_1: "汇聚全球灵感",
      text4_2: "共享叙事",
      text4_3: "协同共建",
      text4_4: "创新故事"
    },
    cont4: {
      title: "文字生成视频"
    },
    cont5: {
      title: "常见使用场景",
      text1: "视频变换与编辑",
      text2: "情绪氛围板",
      text3: "空间视觉预演",
      text4: "角色表演捕捉",
      text5: "虚拟试穿",
      text6: "设计探索",
      text7: "故事分镜",
      text8: "动画样片",
      text9: "生成你自己",
      text10: "视觉特效",
      text_cont1: {
        title: "编辑、变换与生成视频",
        text: "只需用自然语言描述你想要的效果，就能轻松改变场景光线、重塑镜头或主体、添加或移除画面元素等，省去复杂的后期流程。"
      },
      text_cont2: {
        title: "生成专属情绪氛围板",
        text: "将一张图片扩展成完整的活动或项目氛围板。上传一张参考图，即可在同一风格、场景和色调下，持续生成新的图片和视频。"
      },
      text_cont3: {
        title: "几秒钟内完成空间布景",
        text: "无需复杂的 3D 流程或合成操作，只需提供房间的参考图片，再描述你想放入的物品，即可快速完成空间布景效果图。"
      },
      text_cont4: {
        title: "人人都能用的动作捕捉",
        text: "不需要绑定骨骼、手动动画或昂贵的动作捕捉拍摄。只要用任意相机录制一段动作表演，再将其迁移到参考角色上即可。"
      },
      text_cont5: {
        title: "想穿什么都可以试",
        text: "通过参考图功能，你可以为同一主体尝试无数套穿搭。只需一张人物照片和多张服装图片，无需额外拍摄或抠图合成。"
      },
      text_cont6: {
        title: "用图像激发灵感",
        text: "从拾来的物件、纹理和参考图片中寻找灵感，探索建筑、设计等领域的新概念与新方向。"
      },
      text_cont7: {
        title: "让文字提示变成分镜脚本",
        text: "利用单一风格参考和一系列文本提示，在几分钟内生成完整的分镜草图，而不是花费数天时间。"
      },
      text_cont8: {
        title: "把分镜变成动画样片",
        text: "无需高成本、长周期的动画制作。借助图转视频功能，你可以在极短时间内从创意走到高保真概念样片。"
      },
      text_cont9: {
        title: "生成各种风格的“你”",
        text: "用一张自拍即可生成你在不同场景、穿搭和地点中的无数新形象。"
      },
      text_cont10: {
        title: "生成复杂视觉特效",
        text: "通过 Runway Aleph 模型，只需说出你想看到的效果，就能生成复杂的视觉特效。"
      }
    },
    cont6: {
      title: "10× 速度，10% 成本",
      cost_cont1: {
        title: "为速度而生",
        text1: "精简的模型架构",
        text2: "大规模并行计算",
        text3: "极低计算开销",
        text4: "高吞吐量推理管线"
      },
      cost_cont2: {
        title: "硬件加速",
        text1: "GPU 优化渲染",
        text2: "AI 专用硬件",
        text3: "高效内存管理",
        text4: "低延迟输出"
      },
      cost_cont3: {
        title: "10 倍速度，10% 成本",
        text1: "优化的模型结构",
        text2: "分布式计算效率",
        text3: "并行处理管线",
        text4: "硬件加速渲染"
      },
      cost_cont4: {
        title: "价值最大化，成本最小化",
        text1: "优化资源使用率",
        text2: "经济可扩展模型",
        text3: "更低运维成本",
        text4: "更高性价比表现"
      }
    },
    cont7: {
      title1: "我们获得",
      title2: "支持与背书"
    },
    cont8: {
      title: "我们的社区拥有无穷的力量"
    },
    model: {
      title: "HPVideo 支持的模型",
      learn_more: "了解更多",
      li1: {
        title: "Wan2.5",
        text1: "发布日期：2025 年 9 月 24 日（预览版）；“WAN 2.5 正式版”已开放 API 接入和公众体验（后续版本暂无官方预览）。",
        text2: "开发方：阿里巴巴通义实验室（隶属阿里云智能集团的 AI 研发机构）。"
      },
      li2: {
        title: "Ovi",
        text1: "发布日期：2025 年 10 月 15 日（公开预览）；开源版本于 2025 年 10 月 23 日发布（截至 2025 年 11 月尚无官方 “OVI 2” 公告）。",
        text2: "开发方：Character AI（总部位于美国的 AI 实验室），与耶鲁大学研究团队合作开发。"
      },
      li3: {
        title: "VEO 3.1",
        text1: "发布日期：2025 年 8 月 8 日（面向企业用户的测试版）；公众预览自 2025 年 11 月 1 日起逐步开放（目前尚无 “Veo4” 官方公告）。",
        text2: "开发方：Google DeepMind（位于英国的 AI 研究实验室，隶属 Alphabet 公司）。"
      },
      li4: {
        title: "LTX2 Pro",
        text1: "发布日期：2025 年 7 月 20 日（移动端 App 独占测试）；基于 Web 的 API 接口于 2025 年 10 月 30 日上线（截至 2025 年 11 月，尚无 “LTX-3” 官方时间表）。",
        text2: "开发方：Lightricks（以色列的 AI 创意工具公司，以 Facetune/CapCut 竞品而知名）。"
      },
      li5: {
        title: "HAILUO 02",
        text1: "发布日期：2025 年 9 月 30 日（面向企业伙伴的封闭测试）；公共 API 和 Web 演示于 2025 年 11 月 10 日上线（目前尚无 “Hailuo-03” 官方路线图）。",
        text2: "开发方：Minimax（中国的 AI 创业公司，专注多模态生成与企业级 AI 解决方案）。"
      },
      li6: {
        title: "SEEDSNCE V1",
        text1: "发布日期：2025 年 10 月 12 日（面向字节生态应用的内测版）；公共 REST API 与 TikTok Creator Studio 集成于 2025 年 11 月 20 日上线（截至目前尚无 “V2” 官方公告）。",
        text2: "开发方：字节跳动 AI Lab（中国本土的全球科技公司研发部门，专注多模态生成与短视频内容工具）。"
      },
      li7: {
        title: "KLING V2.0",
        text1: "发布日期：2025 年 11 月 5 日（面向开发者的公开测试）；企业 API 接入与自部署选项于 2025 年 11 月 22 日上线（目前尚无 “V3.0” 官方路线图）。",
        text2: "开发方：Kwaivgi（总部位于新加坡的 AI 创业公司，专注面向全球开发者生态的轻量级多模态生成）。"
      },
      li8: {
        title: "PIXVERSE V4.5",
        text1: "发布日期：2025 年 9 月 18 日（面向个人创作者的公开测试）；企业 API 与团队协作功能于 2025 年 11 月 15 日上线（官方 “V5.0” 路线图预计在 2026 年 Q1 推出，主打 4K 输出）。",
        text2: "开发方：Pixverse AI（总部位于美国、拥有全球研发团队的初创公司，专注为创作者和企业提供高质量视觉生成）。"
      },
      li9: {
        title: "SORA (OpenAI)",
        text1: "发布日期：2024 年 2 月（预览版）；目前尚未正式宣布 “SORA 2”（相关版本号多为业界猜测）。",
        text2: "开发方：OpenAI（总部位于美国的 AI 研究实验室）。"
      }
    }
  },
  models: {
    title: "HPVideo",
    text1: "HPVideo 是一个开创性的去中心化 AI 视频生成平台，利用分布式网络提供强大、可信且高效的创作能力。用户可以轻松将文本提示转换为逐帧构建的高质量动态图像。平台通过时间戳验证和透明流程来保护你的创意，确保创作真正属于你。",
    text2: "同时，HPVideo 也致力于打造开放的共创环境，把全球社区连接在一起，在共享叙事的基础上共建创新故事，重新定义协作式数字内容创作。",
    model1: {
      title: "Wan2.5",
      text1: "发布日期：2025 年 9 月 24 日（预览版）；“WAN 2.5 正式版”已开放 API 接入和公众体验（后续版本暂无官方预览）。",
      text2: "开发方：阿里巴巴通义实验室（隶属阿里云智能集团的 AI 研发机构）。",
      text3_1: "功能特性：",
      text3_2: "从文本或图像生成带声音的视频（包含人声、音效、背景音乐），视频时长可延长至 10 秒。",
      text3_3: "采用原生多模态架构，支持复杂指令，如基于物理规律的模拟（物体交互等）以及镜头运动，实现连贯的叙事表现。",
      text3_4: "覆盖多种场景（城市风光、人物动作、自然现象等），并支持全模态创作（图像编辑、文生图等）。",
      text4: "输出：高分辨率视频（480p–1080p，24fps），时间一致性强，纹理细节丰富，支持 HDR 渲染和电影级调色。"
    },
    model2: {
      title: "Ovi",
      text1: "发布日期：2025 年 10 月 15 日（公开预览）；开源版本于 2025 年 10 月 23 日发布（截至 2025 年 11 月尚无官方 “OVI 2” 公告）。",
      text2: "开发方：Character AI（美国的 AI 实验室），与耶鲁大学研究团队合作开发。",
      text3_1: "功能特性：",
      text3_2: "从纯文本或文本+图像输入生成 5 秒钟带声音的视频，具备自然的运动、光照与景深效果。",
      text3_3: "采用双主干跨模态融合架构（总参数量 110 亿，其中 50 亿参数用于语音分支），实现贴近物理规律的交互和顺畅的音画同步。",
      text3_4: "支持多种画幅比例（9:16、16:9、1:1）与场景（如人物动作、日常生活场景等）；开源版本支持自托管部署。",
      text4: "输出：720×720（24fps）视频片段（专业选项最高可达 1080p），时间一致性好、纹理真实，并包含同步的人声或音效。"
    },
    model3: {
      title: "VEO 3.1",
      text1: "发布日期：2025 年 8 月 8 日（面向企业用户的测试版）；公众预览自 2025 年 11 月 1 日起逐步开放（目前尚无 “Veo4” 官方公告）。",
      text2: "开发方：Google DeepMind（位于英国的 AI 研究实验室，隶属 Alphabet 公司）。",
      text3_1: "功能特性：",
      text3_2: "从文本提示生成 15 秒高保真视频，支持多轮提示微调以调整场景细节。",
      text3_3: "基于 Gemini Ultra 2 多模态基础模型，实现物理一致的模拟（例如天气变化、布料运动）以及长镜头空间一致性。",
      text3_4: "与 Google Workspace 集成（如可直接导出至 Slides/Meet），并支持实时风格切换（电影风、动漫风、写实风等）。",
      text4: "输出：1080p 视频（30fps），支持 8 bit HDR 调色，物体细节丰富，并配有同步环境音效（可上传自定义旁白）。"
    },
    model4: {
      title: "LTX2 Pro",
      text1: "发布日期：2025 年 7 月 20 日（移动端 App 独占测试）；基于 Web 的 API 接口于 2025 年 10 月 30 日上线（截至 2025 年 11 月尚无 “LTX-3” 官方时间表）。",
      text2: "开发方：Lightricks（以色列 AI 创意工具公司，以 Facetune/CapCut 竞品而知名）。",
      text3_1: "功能特性：",
      text3_2: "从文本或图像在 20 秒内生成 8 秒视频，针对移动端和社交媒体使用进行了速度优化。",
      text3_3: "采用轻量级、适配边缘设备的模型（20 亿参数），预置 Reels/TikTok 热门风格、复古滤镜和动画贴纸等模板。",
      text3_4: "支持一键导出到 Instagram/TikTok（自动裁剪为 9:16），并提供一键音画同步（内置授权音乐库）。",
      text4: "输出：720p 视频（30fps），运动过渡平滑，色彩经过社交媒体优化，并同步短音频片段。"
    },
    model5: {
      title: "HAILUO 02",
      text1: "发布日期：2025 年 9 月 30 日（面向企业伙伴的封闭测试）；公共 API 与 Web 演示于 2025 年 11 月 10 日上线（目前尚无 “Hailuo-03” 官方路线图）。",
      text2: "开发方：Minimax（中国的 AI 创业公司，专注多模态生成与企业级 AI 解决方案）。",
      text3_1: "功能特性：",
      text3_2: "可从文本、图像或图文混合提示生成 12 秒高一致性视频，对中文语境和本地文化场景有增强适配。",
      text3_3: "采用云-边混合架构（80 亿参数），单条视频推理时间小于 15 秒，并支持自定义模板导入（如营销短片、教学内容等）。",
      text3_4: "可与抖音、视频号等主流平台集成，一键导出；提供一键字幕生成功能（支持普通话、粤语、英语）及合规的声音克隆。",
      text4: "输出：1080p 视频（24fps），具备电影级运动模糊、真实光影效果，并可同步背景音乐、旁白和环境声，支持 MP4/WEBM 格式，方便跨平台分发。"
    },
    model6: {
      title: "SEEDSNCE V1",
      text1: "发布日期：2025 年 10 月 12 日（字节生态内测）；公共 REST API 与 TikTok Creator Studio 集成于 2025 年 11 月 20 日上线（目前尚无 “V2” 官方公告）。",
      text2: "开发方：字节跳动 AI Lab（全球化科技公司的研发部门，专注多模态生成与短内容创作工具）。",
      text3_1: "功能特性：",
      text3_2: "从文本提示生成 10 秒短视频，针对 TikTok 式流行趋势进行优化（如舞蹈挑战、产品展示等）。",
      text3_3: "基于 LightMultimodal 3.0 框架（40 亿参数），提供超快推理（单条视频小于 12 秒）和低延迟 API 响应，对创作者工作流友好。",
      text3_4: "与 TikTok/抖音深度集成（一键导出、自动推荐标签），支持多种风格模板（爆款滤镜、文字特效、动态转场），同时符合全球内容审核政策。",
      text3_5: "主打 480p 高效率输出（平衡画质与速度），可通过内置超分辨率 API 升级到 720p。",
      text4: "输出：480p 视频（30fps，支持 9:16/16:9），运动流畅，色彩经过 TikTok 优化，并同步短音频（授权音乐库、旁白、流行音效），支持 MP4/AVC 格式，适配主流社交平台。"
    },
    model7: {
      title: "KLING V2.0",
      text1: "发布日期：2025 年 11 月 5 日（面向开发者的公开测试）；企业 API 接入和自托管部署选项于 2025 年 11 月 22 日上线（目前尚无 “V3.0” 官方路线图）。",
      text2: "开发方：Kwaivgi（总部位于新加坡的 AI 创业公司，专注面向全球开发者生态的轻量级多模态生成）。",
      text3_1: "功能特性：",
      text3_2: "可从文本、图像或图文混合提示中生成 14 秒高保真视频，并支持跨文化场景适配（原生支持 20+ 种语言提示）。",
      text3_3: "采用模块化 Transformer 架构（60 亿参数），推理时间不超过 18 秒，并支持针对垂直场景（如电商产品视频、教育内容）进行定制微调。",
      text3_4: "提供灵活部署选项：云端 REST API、本地自建部署以及边缘设备集成（兼容 ARM/x86 架构）；内置内容安全过滤，符合 GDPR/CCPA 等隐私法规。",
      text3_5: "支持高级编辑功能：逐帧调整、运动速度控制、音轨替换（兼容免版权音乐库）。",
      text4: "输出：1080p 视频（24/30fps，支持 1:1/9:16/16:9），纹理渲染逼真、空间一致性强，并可同步音频（旁白、环境声、自定义上传音轨），支持 MP4/WEBM/AV1 格式，覆盖多带宽场景。"
    },
    model8: {
      title: "PIXVERSE V4.5",
      text1: "发布日期：2025 年 9 月 18 日（面向个人创作者的公开测试）；企业 API 与团队协作功能于 2025 年 11 月 15 日上线（官方 “V5.0” 路线图预计 2026 年 Q1，重点支持 4K 输出）。",
      text2: "开发方：Pixverse AI（总部位于美国、拥有全球研发团队的初创公司，专注为创作者和企业提供高质量视觉生成）。",
      text3_1: "功能特性：",
      text3_2: "可从文本、图像或分镜稿输入生成 16 秒电影级视频，具备强大的风格控制能力（写实、动漫、赛博朋克、水彩画等，内置 30+ 预设风格并支持自定义上传）。",
      text3_3: "基于 120 亿参数多模态 Transformer，强化时间一致性（减少帧闪烁）和基于物理的渲染（如真实液体流动、布料运动、光线折射）。",
      text3_4: "支持批量视频生成（单次 API 调用最多 50 条），具备智能场景扩展功能（在保持叙事连贯的前提下自动延长视频时长）；并与 Adobe Creative Cloud 集成（提供 Premiere Pro/After Effects 插件）以及 Figma 接入。",
      text3_5: "提供 AI 驱动的后期编辑能力：一键调色、运动稳定、字幕自动生成（支持 40+ 种语言，并进行上下文翻译以适配全球观众）。",
      text4: "输出：1080p 视频（24/30/60fps，支持 1:1/9:16/16:9/21:9），具备 10 bit HDR、电影级动态范围，并支持高保真音频（企业用户可用 5.1 声道）；输出格式包含 MP4/ProRes/AV1（ProRes 为企业版专属）。"
    },
    model9: {
      title: "SORA (OpenAI)",
      text1: "发布日期：2024 年 2 月（预览版）；目前尚未正式宣布 “SORA 2”（相关版本多为行业猜测）。",
      text2: "开发方：OpenAI（美国的 AI 研究实验室）。",
      text3_1: "功能特性：",
      text3_2: "可根据文本提示生成长达 60 秒及以上的高真实感视频。",
      text3_3: "采用基于物理的模拟（如流体动力学、物体交互）并支持长时序叙事。",
      text3_4: "覆盖多种场景（城市风光、人物行为、自然现象等）。",
      text4: "输出：最高可达 1080p 的高清视频，时间一致性强，纹理细节丰富。"
    }
  },
  miners: {
    text1: "参与 GPU 挖矿需要持有一个 NFT 节点。挖矿奖励将在 DEX 上线后约 3–6 个月启动发放。",
    text2: "每年将产出 50 亿枚 HPC 代币用于挖矿奖励。10% 的挖矿奖励即时解锁，其余部分在 180 天内线性解锁。",
    text3: "连接到网络的机器每完成一笔文本转视频请求即可获得 HPC 奖励，但必须在 20 个区块（约 60 秒）内完成视频生成，否则本次请求视为无效。",
    btn1: "购买 HPC",
    btn2: "在 Uniswap 交易 HPC",
    title: "矿机配置要求",
    title1: "GPU",
    text1_1: "至少 1 张显卡，必须为 Nvidia 显卡；推荐 Nvidia GeForce 系列，如 30/40 系列。显存越大，渲染速度越快，收益越高。",
    title2: "内存",
    text2_1: "建议内存容量不低于 16GB",
    title3: "硬盘",
    text3_1: "建议至少预留 100GB 以上可用磁盘空间",
    title4: "网络带宽",
    text4_1: "建议至少 5Mb 以上的网络带宽"
  },
  learn: {
    title: "你的 AI，可以创作一切",
    text: "浏览不断扩充的教程、AMA 与深度解析，轻松将 HPVideo 融入你的创意和制作流程。无论你是刚刚入门还是想进阶掌握复杂技巧，只要有问题，HPVideo Academy 都是你寻找答案的理想起点。",
    text1: "分类",
    text2: "全部"
  },
  help: {
    title: "介绍 SORA",
    text: "我们新一代的媒体生成与世界一致性 AI 模型系列。",
    btn1: "立即体验",
    btn2: "查看文档",
    title1: "你创作所需的一切资源",
    text1: "从这些快速上手主题开始，立刻学习如何使用 HPVideo 的生成视频与创意 AI 工具。",
    desc1: {
      title: "账号与账单",
      text: "管理你的订阅与账单信息",
      btn1: "订阅管理",
      btn2: "账号管理",
      btn3: "积分与额度",
      btn4: "发票"
    },
    desc2: {
      title: "用 HPVideo 创作",
      text: "了解如何使用 HPVideo 的工具和功能完成你的项目",
      btn1: "Gen-4",
      btn2: "工作流",
      btn3: "新手入门",
      btn4: "更多工具"
    },
    desc3: {
      title: "企业版",
      text: "面向企业客户的账号管理信息",
      btn1: "管理员资源",
      btn2: "成员资源"
    },
    desc4: {
      title: "资产与工作区",
      text: "组织与管理你的文件和协作空间",
      btn1: "资产管理",
      btn2: "支持的文件类型",
      btn3: "工作区"
    },
    desc5: {
      title: "故障排查",
      text: "查找常见技术问题与错误信息的解决方案",
      btn1: "订阅管理",
      btn2: "平台故障排查",
      btn3: "获取技术支持"
    },
    desc6: {
      title: "社区、隐私与内容政策",
      text: "了解 HPVideo 社区项目及平台使用与内容标准相关指南",
      btn1: "教育版 HPVideo",
      btn2: "社区",
      btn3: "信任与安全"
    }
  },
  faqs: {
    title: "常见问题",
    text: "FAQ 问答",
    qs1: {
      title: "1. 什么是 HPVideo？",
      text: 'HPVideo 是部署在 BNB Chain 上的去中心化 AI 文本转视频平台，旨在为 AI Agent 时代打造未来的“视频基础设施层”。用户只需连接钱包、选择视频模型（如 SORA、WAN、KLING）、输入提示词与时长、支付少量 USDT，即可生成高质量视频——无需邮箱注册、实名认证或提交任何个人信息。'
    },
    qs2: {
      title: "2. HPVideo 如何生成 AI 视频？",
      text: 'HPVideo 是部署在 BNB Chain 上的去中心化 AI 文本转视频平台，旨在为 AI Agent 时代打造未来的“视频基础设施层”。用户只需连接钱包、选择视频模型（如 SORA、WAN、KLING）、输入提示词与时长、支付少量 USDT，即可生成高质量视频——无需邮箱注册、实名认证或提交任何个人信息。'
    },
    qs3: {
      title: "3. 为什么 HPVideo 使用钱包登录？",
      text: 'HPVideo 不需要邮箱或中心化账号。基于钱包的访问方式更能保护用户隐私、提升安全性，并让 Web2 与 Web3 用户都可以更轻松地上手。'
    },
    qs4: {
      title: "4. HPVideo 是如何做到去中心化的？",
      text: '视频请求、支付与时间戳都会记录在 BNB Chain 上，生成过程由分布式算力完成。这种设计确保了过程透明、结果可验证，以及内容所有权可信。'
    },
    qs5: {
      title: "5. HPVideo 支持哪些 AI 模型？",
      text: 'HPVideo 支持 WAN 2.5、SORA 2、OVI、VEO 3.1、LTX 2 Pro、KLING V2.0、PIXVERSE V4.5 等多种模型。每个模型都擅长不同的视觉风格和创作场景。'
    },
    qs6: {
      title: "6. 生成一段视频需要多少钱？",
      text: '费用取决于模型与时长。大多数视频费用在 0.3–1 USDT 之间，并通过用户的 BNB Chain 钱包支付。'
    },
    qs7: {
      title: "7. 用户是否拥有自己生成的视频？",
      text: '是的。所有生成的视频都归属对应的钱包地址所有。链上的时间戳可以作为原创性与所有权的可验证证明。'
    },
    qs8: {
      title: "8. Web2 创作者也可以使用 HPVideo 吗？",
      text: '可以。流程非常简单：连接钱包 → 输入提示词 → 生成视频。无需任何加密货币知识或账号注册。'
    },
    qs9: {
      title: "9. HPVideo 有代币吗？",
      text: '会有。HPVideo 将发行 $HPC 代币，用于治理、激励、算力参与以及生态实用场景。更多细节将于官方白皮书中公布。'
    },
    qs10: {
      title: "10. HPVideo 的长期目标是什么？",
      text: 'HPVideo 旨在成为面向全球创作者、AI Agent 和 Web3 应用的去中心化视频基础设施层，提供透明的生成过程、可验证的所有权以及多模型的创意生态。'
    }
  },
  footer: {
    title: "实用链接",
    meau1: "Github",
    meau2: "矿工",
    meau3: "白皮书",
    meau4: "常见问题",
    meau5: "$HPC",
    title1: "开始体验 HPVideo",
    btn1: "试用 HPVideo",
    btn2: "观看演示",
    footer_bottom: "2025 HPVideo. 版权所有。"
  }
}