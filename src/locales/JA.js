export default {
  meau: {
    nav1: "モデル",
    nav2: "マイナー",
    nav3: "学習",
    nav4: "クリエイター",
    nav5: "ブログ",
    nav6: "アカデミー",
    nav7: "ヘルプセンター",
    nav8: "HPVideo の使い方",
    nav9: "HPVideo へ移動"
  },
  home: {
    cont1: {
      title1: "HPVideo",
      title2: "BNBチェーン上の分散型AIビデオ生成プラットフォーム",
      title3: "HPVideoは、BNBチェーン上のウォレットベースの分散型AIビデオ生成プラットフォームです。複数のAIモデルを活用し、高速かつ低コストでビデオを作成できます。メールアドレスや個人情報は不要です",
      text1: "10倍の速度",
      text2: "料金",
      btn: "作成を始める",
      model1: {
        text: "特徴と利点：物理世界の理解とシミュレーション能力で業界の基準となるモデルです。複雑なシーン、一貫したキャラクター、多角的なカメラアングルを備えた映画レベルのビデオを生成し、現実の物理法則に基づいた動きを正確に再現します。",
        tips: "例：霧が立ち込める北極の森から雄大なマンモスがゆっくりと現れる映画予告編。長い毛が自然に揺れ、夕陽の中で白い息を吐きながら歩きます。カメラは動的に移動し、映画のようなスケール感を演出します。"
      },
      model2: {
        text: "特徴と利点：1分以上の高品質で一貫性のある長尺映像を生成できます。キャラクターやスタイルが映像全体で安定しており、短編ストーリーの制作に最適です。",
        tips: "例：孤独な宇宙飛行士が色鮮やかな未知の惑星で最初の一歩を踏み出す60秒の映像。発光する苔を踏む靴のクローズアップから始まり、ヘルメット越しに感嘆する表情を映し、最後は2つの月が照らす幻想的な風景のワイドショットへ。"
      },
      model3: {
        text: "特徴と利点：高度な物理エンジンと高ダイナミックレンジによるリアルなレンダリングで知られています。流体（例：水、煙）や光の反射など、複雑な動きを正確に再現できます。",
        tips: "例：強い日差しの下で水風船が壁にぶつかって破裂するスローモーション映像。衝突の瞬間から水滴が飛び散るまでのディテール、壁面に反射する光の変化までをリアルに描写します。"
      },
      model4: {
        text: "特徴と利点：動きの自然さとディテールの表現が両立されたモデルです。キャラクターの表情、皮膚や布、金属などの質感、環境の細部までもリアルに表現します。",
        tips: "例：熟練した職人が熱いガラスを加工するクローズアップ映像。溶けるガラスの形状、赤く輝く光、工具の質感、職人の集中した表情まで細かく描かれます。"
      },
      model5: {
        text: "特徴と利点：高度なコントロール機能を備えた統合型AIビデオ制作スイート。カメラの動きやキャラクターの一貫性を調整でき、滑らかな人物の動作と感情を描くストーリーテリング動画に適しています。",
        tips: "例：探偵が暗い図書館でほこりをかぶった古い本を開くシーン。慎重な表情、光の筋に舞う埃、ページの間から現れる地図が劇的な光影の中で表現されます。"
      },
      model6: {
        text: "特徴と利点：SNSの縦動画から映画スクリーンまで、さまざまな解像度に対応し、高品質のオーディオと映像を完全に同期させることができます。",
        tips: "例：サイバーパンク風の9:16縦動画。ネオンに照らされた屋上でDJが演奏し、群衆と光の演出が音楽のリズムと完全に同期します。"
      },
      model7: {
        text: "特徴と利点：大規模な動的シーンのリアルなレンダリングに優れています。嵐、波、戦場、都市交通など、複雑な動きを伴う場面を物理的に正確な光と影で描写します。",
        tips: "例：黄昏時の中世の戦場を俯瞰するショット。数千の兵士、矢の雨、煙、炎、風に揺れる旗など、映画のようなスケール感で表現されます。"
      },
      model8: {
        text: "特徴と利点：マルチカメラの構成とスムーズな切り替えに特化しています。自動でクローズアップ・中景・遠景を組み合わせ、広告やショートムービー制作に最適です。",
        tips: "例：30秒の無声映画風ストーリー。古い手紙のクローズアップ→雨の中を走る郵便配達員→手紙を受け取った人物の笑顔。カットのつながりが滑らかで物語性があります。"
      }
    },
    cont2: {
      title: "何を作りたいですか？",
      text1: "白い羽が雷鳴の中を舞い、嵐の渦に吸い込まれていく。混沌の空に穏やかな軌跡を残します。",
      text2: "黒いインクが透明な水に落ち、宇宙の星雲のように広がる。静かなガラスの中で抽象的な深海が生まれます。",
      text3: "古い地図で作った紙の船が雨の排水溝を流れ、ネオンの光に照らされながら都市の灯を映します。",
      text4: "折り鶴がゆっくりと開き、一枚の平らな紙に戻る。折り目には記憶が刻まれています。",
      text5: "未来都市の反射が水たまりに映り、雨の一滴が波紋を広げ、都市の像が分裂し再構成されます。"
    },
    cont3: {
      title1: "分散型インテリジェンスコア",
      text1_1: "分散計算",
      text1_2: "AI統合",
      text1_3: "信頼できる生成",
      text1_4: "効率的な創作",
      title2: "テキストから動く映像へ",
      text2_1: "テキスト入力",
      text2_2: "フレーム構築",
      text2_3: "映像生成",
      text2_4: "高品質出力",
      title3: "創作の真の所有権",
      text3_1: "創作タイムスタンプ",
      text3_2: "透明な生成プロセス",
      text3_3: "価値保護",
      text3_4: "所有権保証",
      title4: "オープンコラボレーション",
      text4_1: "世界中のインスピレーションを結ぶ",
      text4_2: "共有された物語",
      text4_3: "協働創作",
      text4_4: "革新的なストーリー"
    },
    cont4: {
      title: "テキストからビデオを生成"
    },
    cont5: {
      title: "主な利用シーン",
      text1: "ビデオ編集・変換",
      text2: "ムードボード生成",
      text3: "空間ビジュアルプレビュー",
      text4: "動作キャプチャ",
      text5: "バーチャル試着",
      text6: "デザイン探索",
      text7: "ストーリーボード",
      text8: "アニメーションプリビズ",
      text9: "自分自身を生成",
      text10: "ビジュアルエフェクト",
      text_cont1: {
        title: "自然言語での映像編集",
        text: "言葉で指示するだけで照明、構図、対象などを変化させ、複雑なポストプロセスを不要にします。"
      },
      text_cont2: {
        title: "ムードボードの作成",
        text: "1枚の参考画像から、同じトーンやスタイルを持つ新しい画像や動画を連続生成できます。"
      },
      text_cont3: {
        title: "数秒で空間演出を完成",
        text: "3D建模なしで、部屋の写真と簡単な説明だけで空間レイアウトを生成します。"
      },
      text_cont4: {
        title: "誰でもできる動作キャプチャ",
        text: "高価なモーションキャプチャ装置は不要。カメラで動きを撮影し、キャラクターに適用できます。"
      },
      text_cont5: {
        title: "仮想試着を体験",
        text: "1枚の人物写真と服の画像だけで、無限にコーディネートを試すことができます。"
      },
      text_cont6: {
        title: "画像から発想を得る",
        text: "素材や写真から建築・デザインの新しいアイデアを探ります。"
      },
      text_cont7: {
        title: "テキストでストーリーボードを作成",
        text: "数行のテキストで一貫したスタイルのストーリーボードをすぐに作れます。"
      },
      text_cont8: {
        title: "ストーリーボードを動画に変換",
        text: "画像から動画への変換機能で、短時間で高品質なコンセプト映像を制作可能です。"
      },
      text_cont9: {
        title: "さまざまなスタイルの“自分”を生成",
        text: "1枚のセルフィーから、異なる背景・衣装の自分を無限に作成。"
      },
      text_cont10: {
        title: "複雑なVFXを生成",
        text: "Runway Aleph モデルにより、テキストだけで複雑な視覚効果を作り出せます。"
      }
    },
    cont6: {
      title: "10倍の速度、10%のコスト",
      cost_cont1: {
        title: "スピード重視の設計",
        text1: "軽量化モデル構造",
        text2: "大規模並列処理",
        text3: "低計算コスト",
        text4: "高スループットパイプライン"
      },
      cost_cont2: {
        title: "ハードウェアアクセラレーション",
        text1: "GPU最適化レンダリング",
        text2: "AI専用ハードウェア",
        text3: "効率的メモリ管理",
        text4: "低レイテンシ出力"
      },
      cost_cont3: {
        title: "10倍速、10%コスト",
        text1: "最適化モデル構造",
        text2: "分散処理効率",
        text3: "並列パイプライン",
        text4: "GPUアクセラレートレンダリング"
      },
      cost_cont4: {
        title: "価値最大化、コスト最小化",
        text1: "リソース効率化",
        text2: "経済的スケーラビリティ",
        text3: "低運用コスト",
        text4: "高コストパフォーマンス"
      }
    },
    cont7: {
      title1: "受賞・",
      title2: "サポートと評価"
    },
    cont8: {
      title: "私たちのコミュニティは無限の力を持っています"
    },
    model: {
      title: "HPVideos 対応モデル",
      learn_more: "詳細はこちら",
      li1: {
        title: "Wan2.5",
        text1: "リリース: 2025年9月24日（プレビュー版）; 「WAN 2.5 正式版」では API アクセスと一般公開が開始されました（後続バージョンの公式プレビューはありません）。",
        text2: "開発元: Alibaba (中国) Tongyi Lab (Alibaba Cloud Intelligence Group 傘下の AI 研究開発機関)。"
      },
      li2: {
        title: "Ovi",
        text1: "リリース: 2025年10月15日（パブリックプレビュー）; オープンソース版は 2025年10月23日にリリースされました（2025年11月現在、「OVI 2」の公式発表はありません）。",
        text2: "開発元: Character AI (米国を拠点とする AI ラボ) がイェール大学の研究チームと共同で開発しています。"
      },
      li3: {
        title: "VEO 3.1",
        text1: "リリース: 2025年8月8日（エンタープライズユーザー向けベータ版アクセス）; パブリックプレビューは2025年11月1日に開始（現時点では「Veo4」の公式発表はありません）。",
        text2: "開発元: Google DeepMind（英国に拠点を置くAI研究機関、Alphabet Inc.傘下）。"
      },
      li4: {
        title: "LTX2 Pro",
        text1: "リリース: 2025年7月20日（モバイルアプリ限定ベータ版）; ウェブベースのAPIアクセスは2025年10月30日に開始（2025年11月現在、「LTX-3」の公式タイムラインはありません。）",
        text2: "開発元: Lightricks（イスラエルに拠点を置くAIクリエイティブツール企業、Facetune/CapCutの競合製品で知られる）。"
      },
      li5: {
        title: "HAILUO 02",
        text1: "リリース: 2025年9月30日（エンタープライズパートナー向けクローズドベータ版）；パブリックAPIとウェブデモは2025年11月10日にリリース（現時点では「Hailuo-03」の公式ロードマップは未定）",
        text2: "開発元: Minimax（マルチモーダル生成とエンタープライズAIソリューションを専門とする中国拠点のAIスタートアップ企業）"
      },
      li6: {
        title: "SEEDSNCE V1",
        text1: "リリース: 2025年10月12日（ByteDanceエコシステムアプリ向け社内ベータ版）。パブリックREST APIとTikTok Creator Studioとの統合は2025年11月20日に開始（現時点では「V2」の公式発表はありません）。",
        text2: "開発元: ByteDance AI Lab（中国に拠点を置くグローバルテクノロジー企業のR&D部門。マルチモーダル生成と短編コンテンツツールを専門としています。）"
      },
      li7: {
        title: "KLING V2.0",
        text1: "リリース: 2025年11月5日（開発者向けパブリックベータ版）; エンタープライズAPIアクセスとセルフホスト型デプロイメントオプションは2025年11月22日に開始（現時点では「V3.0」の公式ロードマップは未定）",
        text2: "開発元: Kwaivgi（シンガポールに拠点を置くAIスタートアップ企業。グローバルな開発者エコシステム向けの軽量マルチモーダル生成に注力）。"
      },
      li8: {
        title: "PIXVERSE V4.5",
        text1: "リリース: 2025年9月18日（個人クリエイター向けパブリックベータ版）; エンタープライズAPIとチームコラボレーション機能は2025年11月15日にリリース（公式の「V5.0」ロードマップは2026年第1四半期に公開予定。4K出力に重点を置く）。",
        text2: "開発元: Pixverse AI（グローバルな研究開発チームを擁する米国のスタートアップ企業。クリエイターと企業向けの高品質ビジュアル生成を専門とする）"
      },
      li9: {
        title: "SORA (OpenAI)",
        text1: "リリース: 2024年2月（プレビュー）; 「SORA 2」は正式発表されていない（推測に基づくバージョンアップの可能性あり）。",
        text2: "開発元: OpenAI（米国のAI研究機関）。",
      }
    }
  },
  models: {
    title: "HPVideo",
    text1: "HPVideoは、分散ネットワーク上で動作する分散型AIビデオ生成プラットフォームです。テキストプロンプトを入力するだけで、フレーム単位で構築された高品質な映像を生成できます。生成プロセスはタイムスタンプで検証され、すべての作品の所有権が明確に保証されます。",
    text2: "さらにHPVideoは、世界中のクリエイターをつなぐオープンな共同制作環境を提供し、共有された物語を通して新しい創作文化を築いていきます。",
    model1: {
      title: "Wan2.5",
      text1: "リリース日：2025年9月24日（プレビュー版）。WAN 2.5正式版はAPIおよび一般公開済みです。",
      text2: "開発元：Alibaba Tongyi Lab（アリババクラウド傘下のAI研究所）。",
      text3_1: "機能概要：",
      text3_2: "テキストまたは画像から音声付きの映像を生成（音声・効果音・BGM対応）、最長10秒まで。",
      text3_3: "マルチモーダル構造を採用し、物理ベースのシミュレーションとカメラ移動をリアルに表現。",
      text3_4: "都市・人物・自然など多様なシーンに対応し、画像編集やテキストから画像生成も可能。",
      text4: "出力：480p～1080p（24fps）の高解像度映像、HDRカラーサポート、一貫した時系列表現。"
    },
    model2: {
      title: "Ovi",
      text1: "リリース日：2025年10月15日（パブリックプレビュー）、10月23日にオープンソース化。",
      text2: "開発元：Character AI（米国のAI研究所、イェール大学チームと共同開発）。",
      text3_1: "機能概要：",
      text3_2: "テキストまたは画像入力から5秒間の音付き映像を生成。自然な動きと照明、被写界深度を再現。",
      text3_3: "110億パラメータ構成のデュアルバックボーン構造で、音声同期精度を向上。",
      text3_4: "9:16、16:9、1:1など複数の比率に対応し、セルフホスティング可能。",
      text4: "出力：720×720（24fps）、プロ版は1080p対応、音声同期と物理的一貫性が優秀。"
    },
    model3: {
      title: "VEO 3.1",
      text1: "リリース日：2025年8月8日（企業向けテスト版）、11月1日より一般プレビュー開始。",
      text2: "開発元：Google DeepMind（英国拠点、Alphabet傘下）。",
      text3_1: "機能概要：",
      text3_2: "テキストプロンプトから最長15秒の高精細映像を生成、マルチプロンプトでシーンを調整可能。",
      text3_3: "Gemini Ultra 2マルチモーダルモデルを採用し、天候や布の動きなど物理的リアリズムを再現。",
      text3_4: "Google Workspaceと統合し、SlidesやMeetへ直接出力可能。リアルタイムスタイル切替も対応。",
      text4: "出力：1080p（30fps）HDR映像、環境音やナレーションの同期サポート。"
    },
    model4: {
      title: "LTX2 Pro",
      text1: "リリース日：2025年7月20日（モバイル限定テスト）、10月30日にWeb API公開。",
      text2: "開発元：Lightricks（イスラエルのAIクリエイティブ企業、Facetune/CapCut競合）。",
      text3_1: "機能概要：",
      text3_2: "テキストまたは画像入力で20秒以内に8秒映像を生成。モバイル向けに最適化。",
      text3_3: "軽量2Bパラメータモデルで、Reels/TikTok向けテンプレートを内蔵。",
      text3_4: "SNSへワンクリックで共有、音声と映像の自動同期。",
      text4: "出力：720p（30fps）、ソーシャルメディア向け色調最適化済み短尺映像。"
    },
    model5: {
      title: "HAILUO 02",
      text1: "リリース日：2025年9月30日（クローズドテスト）、11月10日にAPIとWebデモ公開。",
      text2: "開発元：Minimax（中国AIスタートアップ、多モーダル生成に特化）。",
      text3_1: "機能概要：",
      text3_2: "テキスト・画像・複合入力から12秒間の高一貫性映像を生成。中国語環境に最適化。",
      text3_3: "クラウド-エッジ混合構造（80億パラメータ）、1件の推論が15秒未満。",
      text3_4: "DouyinやWeChatと統合、自動字幕生成（中国語・英語対応）、音声クローン可。",
      text4: "出力：1080p（24fps）、映画レベルの動きと照明、BGM/ナレーション同期。"
    },
    model6: {
      title: "SEEDSNCE V1",
      text1: "リリース日：2025年10月12日（ByteDance内テスト）、11月20日にTikTok Creator Studio API公開。",
      text2: "開発元：ByteDance AI Lab（グローバルAI研究部門）。",
      text3_1: "機能概要：",
      text3_2: "テキスト入力から10秒動画を生成。TikTokのトレンド（ダンス、商品紹介）に最適化。",
      text3_3: "LightMultimodal 3.0（40億パラメータ）を採用し、推論12秒以内。",
      text3_4: "TikTok/抖音連携、自動タグ推薦、グローバルコンテンツガイドライン準拠。",
      text3_5: "デフォルト出力480p、アップスケールで720p対応。",
      text4: "出力：480p（30fps、9:16/16:9対応）、TikTok最適化色彩、音楽・効果音同期。"
    },
    model7: {
      title: "KLING V2.0",
      text1: "リリース日：2025年11月5日（開発者向けテスト）、11月22日企業API・自動ホスティング公開。",
      text2: "開発元：Kwaivgi（シンガポール拠点のAIスタートアップ）。",
      text3_1: "機能概要：",
      text3_2: "テキスト・画像入力で14秒映像を生成、20言語以上のプロンプトに対応。",
      text3_3: "モジュール型トランスフォーマー（60億パラメータ）、産業別カスタム調整可能。",
      text3_4: "クラウドAPI・ローカル展開・エッジデバイス対応、GDPR/CCPA準拠。",
      text3_5: "高度な編集機能：フレーム調整・速度制御・音声差し替えなど。",
      text4: "出力：1080p（24/30fps）、MP4/WEBM/AV1形式、リアルな質感描写。"
    },
    model8: {
      title: "PIXVERSE V4.5",
      text1: "リリース日：2025年9月18日（一般公開テスト）、11月15日企業向け機能追加。",
      text2: "開発元：Pixverse AI（米国本社のグローバル開発チーム）。",
      text3_1: "機能概要：",
      text3_2: "テキスト・画像・絵コンテから16秒映画級映像を生成、30以上のプリセットスタイル搭載。",
      text3_3: "120億パラメータモデル、物理レンダリングと時間整合性を強化。",
      text3_4: "一括生成最大50件、Adobe/Figma統合プラグイン提供。",
      text3_5: "AIカラー補正・手ブレ補正・字幕自動翻訳（40言語対応）。",
      text4: "出力：1080p（24/30/60fps）、HDR10bit、MP4/ProRes/AV1形式。"
    },
    model9: {
      title: "SORA (OpenAI)",
      text1: "リリース日：2024年2月（プレビュー版）。SORA 2は未発表。",
      text2: "開発元：OpenAI（米国のAI研究所）。",
      text3_1: "機能概要：",
      text3_2: "テキスト入力から最長60秒以上の高現実感映像を生成。",
      text3_3: "物理ベースのシミュレーションと長時間ストーリー構築をサポート。",
      text3_4: "都市・人物・自然など多様なテーマに対応。",
      text4: "出力：最大1080p、リアルなテクスチャと時間整合性を実現。"
    }
  },
  miners: {
    text1: "GPUマイニングに参加するにはNFTノードが必要です。報酬の分配はDEX上場から約3〜6か月後に開始されます。",
    text2: "年間50億HPCトークンがマイニング報酬として発行されます。10％は即時、残りは180日間で線形リリースされます。",
    text3: "ネットワークに接続されたマシンは、各テキスト→ビデオ要求を完了するたびにHPCを獲得します。20ブロック（約60秒）以内に生成できない場合は無効となります。",
    btn1: "HPCを購入",
    btn2: "UniswapでHPCを取引",
    title: "マイナー仕様",
    title1: "GPU",
    text1_1: "Nvidia GPUが1枚以上必要。GeForce 30/40シリーズ推奨。VRAMが大きいほど高速で収益性が高い。",
    title2: "メモリ",
    text2_1: "16GB以上を推奨",
    title3: "ストレージ",
    text3_1: "100GB以上の空き容量を推奨",
    title4: "ネットワーク帯域",
    text4_1: "最低5Mb以上の帯域を推奨"
  },
  learn: {
    title: "あなたのAIで、すべてを創造する",
    text: "チュートリアル、AMA、解説を通じてHPVideoの使い方を学びましょう。初心者から上級者まで、誰でも自分の制作フローに組み込むことができます。",
    text1: "カテゴリー",
    text2: "すべて"
  },
  help: {
    title: "SORAの紹介",
    text: "世界と整合する次世代メディア生成AIシリーズ。",
    btn1: "今すぐ体験",
    btn2: "ドキュメントを見る",
    title1: "創作に必要なすべてのリソース",
    text1: "HPVideoのAIツールとワークフローの使い方を学べます。",
    desc1: {
      title: "アカウントと請求",
      text: "購読・請求情報を管理します。",
      btn1: "購読管理",
      btn2: "アカウント管理",
      btn3: "ポイントと残高",
      btn4: "請求書"
    },
    desc2: {
      title: "HPVideoで創作",
      text: "HPVideoのツールと機能を使ってプロジェクトを完成させる方法を学びます。",
      btn1: "Gen-4",
      btn2: "ワークフロー",
      btn3: "初心者向けガイド",
      btn4: "その他のツール"
    },
    desc3: {
      title: "企業向け",
      text: "企業アカウント管理情報",
      btn1: "管理者リソース",
      btn2: "メンバーリソース"
    },
    desc4: {
      title: "アセットとワークスペース",
      text: "ファイルとコラボスペースの整理・管理。",
      btn1: "アセット管理",
      btn2: "対応ファイル形式",
      btn3: "ワークスペース"
    },
    desc5: {
      title: "トラブルシューティング",
      text: "一般的な技術的問題やエラーの解決策を探します。",
      btn1: "購読管理",
      btn2: "プラットフォーム診断",
      btn3: "技術サポート"
    },
    desc6: {
      title: "コミュニティ、プライバシー、コンテンツポリシー",
      text: "HPVideoの利用・ガイドラインを確認します。",
      btn1: "教育版HPVideo",
      btn2: "コミュニティ",
      btn3: "信頼と安全"
    }
  },
  faqs: {
    title: "よくある質問",
    text: "FAQ",
    qs1: {
      title: "1. HPVideoとは？",
      text: "HPVideoはBNBチェーン上の分散型AIテキスト→ビデオプラットフォームです。ウォレットを接続し、モデル（SORA、WAN、KLINGなど）を選び、プロンプトと長さを指定して少額のUSDTを支払うだけで、高品質な映像を生成できます。"
    },
    qs2: {
      title: "2. どのようにしてAI映像を生成しますか？",
      text: "HPVideoは分散計算ネットワーク上で映像生成を行います。すべてのリクエスト、支払い、結果はブロックチェーン上で記録されます。"
    },
    qs3: {
      title: "3. なぜウォレットログインを採用していますか？",
      text: "HPVideoはメールや中央アカウントを必要としません。ウォレットによるアクセスはプライバシーとセキュリティを強化します。"
    },
    qs4: {
      title: "4. 分散化はどのように実現されていますか？",
      text: "ビデオ生成の全プロセスがBNBチェーンに記録され、ノードが分散的に処理します。"
    },
    qs5: {
      title: "5. どのAIモデルを利用できますか？",
      text: "WAN 2.5、SORA、OVI、VEO 3.1、LTX2 Pro、KLING V2.0、PIXVERSE V4.5などをサポートしています。"
    },
    qs6: {
      title: "6. 動画生成のコストは？",
      text: "モデルと長さにより異なりますが、多くは0.3〜1 USDT程度です。BNBチェーンウォレットで支払います。"
    },
    qs7: {
      title: "7. 生成した映像の所有権は？",
      text: "すべての作品は生成したウォレットの所有物です。タイムスタンプで著作証明が可能です。"
    },
    qs8: {
      title: "8. Web2ユーザーも利用できますか？",
      text: "はい。ウォレットを接続してプロンプトを入力するだけで映像を生成できます。"
    },
    qs9: {
      title: "9. HPVideoトークンはありますか？",
      text: "$HPCトークンが発行され、ガバナンス・報酬・計算資源参加・ユーティリティに使用されます。"
    },
    qs10: {
      title: "10. HPVideoの長期目標は？",
      text: "HPVideoは世界中のクリエイター、AIエージェント、Web3アプリのための分散型ビデオ基盤を目指しています。"
    }
  },
  footer: {
    title: "便利なリンク",
    meau1: "Github",
    meau2: "マイナー",
    meau3: "ホワイトペーパー",
    meau4: "FAQ",
    meau5: "$HPC",
    title1: "HPVideoを始めよう",
    btn1: "HPVideoを試す",
    btn2: "デモを見る",
    footer_bottom: "2025 HPVideo. All Right Researved"
  }
}